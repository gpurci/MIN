#  Genetic Algorithm Framework

This project implements a **modular Genetic Algorithm (GA)** in Python for solving complex optimization problems such as the **Travelling Salesman Problem (TSP)** and **Travelling Thief Problem (TTP)**.  
It’s designed to be flexible — each stage of the algorithm (population initialization, selection, crossover, mutation, etc.) is modular and easy to configure.

---

## Project Structure

| File | Description |
|------|--------------|
| `algoritm_genetic.py` | The main GA manager that coordinates all algorithm steps. |
| `metrics.py` | Computes problem-specific metrics (distance, time, profit, etc.). |
| `init_population.py` | Generates the initial population (random or heuristic). |
| `fitness.py` | Calculates the fitness (quality) of each individual/solution. |
| `select_parent.py` | Handles how parents are selected for reproduction. |
| `crossover.py` | Performs genetic crossover between parents. |
| `mutate.py` | Applies random mutations for exploration. |
| `callback.py` | Logs evolution metrics per generation into a CSV file. |
| `root_GA.py` | Defines general GA parameters and constants. |
| `genetic_AO_man.py` | Example runner script that ties everything together. |

---

## How to Run

Run the example script:

```bash
python genetic_AO_man.py

```
---
This will:
1. Generate a **map and dataset** (cities, distances, etc.).
2. Configure and run the **Genetic Algorithm**.
3. Log progress in a user filename
4. Optionally visualize the **best routes** discovered during optimization.

---

## Basic Configuration

When creating the `GeneticAlgorithm` object, you can control every stage of the process through configuration dictionaries.

Example:

```python
ttp = GeneticAlgorithm(
    name="test",
    extern_commnad_file="extern_command.cmd",
    metric={"method": "TSP"},
    init_population={"method": "TSP_aleator"},
    fitness={"method": "TSP_f1score"},
    select_parent={
        "select_parent1": {"method": "turneu"},
        "select_parent2": {"method": "turneu_choice"},
    },
    crossover={"method": "mixt"},
    mutate={"method": "mixt"},
    callback="logs/history.csv"
)
```
Each configuration specifies how one component of the genetic algorithm behaves.

---

## ️ Configuration Options

| Parameter | Purpose | Example Values |
|------------|----------|----------------|
| **`metric`** | Defines how the problem is evaluated (distance, time, profit, etc.). | `"TSP"` or `"TTP"` |
| **`init_population`** | Defines how the initial population (the starting solutions) is generated. | `"TSP_aleator"` (random), `"TTP_vecin"` (heuristic) |
| **`fitness`** | Determines how the “quality” of a solution is measured. | `"TSP_f1score"`, `"TSP_norm"`, `"TTP_linear"`, `"TTP_exp"` |
| **`select_parent1`, `select_parent2`** | Define how parents are chosen for reproduction. Two strategies can be used for better diversity. | `"turneu"`, `"turneu_choice"`, `"roata"` |
| **`crossover`** | Defines how two parents are combined into a child (genetic recombination). | `"split"`, `"perm_sim"`, `"mixt"` |
| **`mutate`** | Mutation strategy for introducing randomness and variation in offspring. | `"swap"`, `"inversion"`, `"mixt"` |
| **`callback`** | Path to the CSV file used for logging performance metrics across generations. | `"logs/history.csv"` |
| **`extern_commnad_file`** | Optional file that allows stopping or controlling the algorithm externally. | `"extern_command.cmd"` |

---

##  GA Parameters

Once the algorithm is configured, you can fine-tune its runtime parameters with:

```python
ttp.setParameters(
    GENERATIONS=5000,      # Number of generations (iterations)
    POPULATION_SIZE=1000,  # Number of individuals in each generation
    MUTATION_RATE=0.05,    # Probability of mutation
    CROSSOVER_RATE=0.99,   # Probability of crossover
    SELECT_RATE=0.99,      # Fraction of population used for selection
    ELITE_SIZE=50          # Top individuals preserved automatically each generation
)
```
These control the evolution process — larger populations and more generations improve results but increase runtime.

---

## TTP Generator Module

The file **`ttp_generator.py`** provides the `TTPGenerator` class — a helper used to **load and prepare data** for the  
**Travelling Thief Problem (TTP)** and **visualize routes** generated by the Genetic Algorithm.

This module handles:
- Reading city coordinates and item data from `.csv` files.  
- Computing pairwise distances between all cities.  
- Linking each city with assigned item **profit** and **weight**.  
- Generating visual map images to display routes.

---

### How It Works

The `TTPGenerator` class builds a dataset that your GA can directly use.

```python
from ttp_generator import TTPGenerator

# Initialize with dataset folder path
ttp_generator = TTPGenerator(path="datasets")

# Load city coordinates and item data (tab-separated CSVs)
dataset = ttp_generator("nodes.csv", "items.csv")

# The dataset contains:
# - GENOME_LENGTH: number of cities
# - distance: matrix of pairwise distances
# - coords: list of (x, y) positions
# - item_profit: array of profit values
# - item_weight: array of item weights
```

You can then pass this `dataset` to the main Genetic Algorithm runner:

```python
from genetic_AO_man import GeneticAlgorithm

# Create and configure the Genetic Algorithm instance
ttp = GeneticAlgorithm(
    name="ttp_example",
    metric={"method": "TTP"},
    init_population={"method": "TTP_aleator"},
    fitness={"method": "TTP_linear"},
    select_parent={
        "select_parent1": {"method": "turneu"},
        "select_parent2": {"method": "roata"},
    },
    crossover={"method": "mixt"},
    mutate={"method": "mixt"},
    callback="logs/history.csv"
)

# Define algorithm parameters
ttp.setParameters(
    GENERATIONS=1000,
    POPULATION_SIZE=500,
    MUTATION_RATE=0.05,
    CROSSOVER_RATE=0.95,
    SELECT_RATE=0.9,
    ELITE_SIZE=50
)

# Run the algorithm using the TTP dataset
ttp(dataset)
```
This will execute a **TTP optimization** where each generation improves the trade-off between **travel distance** and **total profit collected**.  
The algorithm uses evolutionary principles — **selection, crossover, and mutation** — to evolve increasingly efficient solutions.  
During the process, results are continuously logged and can later be analyzed or visualized.

---

###  Outputs

When you run the algorithm:
- Progress is logged in **`logs/history.csv`**  
- Console output shows each generation’s best fitness and score  
- (Optional) Route visualization displays the best found path on the map  

**Example console output:**
```commandline
Running Genetic Algorithm (TTP)
Generation 50: best_profit=245.7, distance=312.4, fitness=0.89
Generation 51: best_profit=249.3, distance=308.1, fitness=0.91
...
Optimization completed after 1000 generations.
```
###      Adjusting Parameters for TTP

You can fine-tune the Genetic Algorithm parameters in `genetic_AO_man.py` or directly in your own script to control runtime and performance:

```python
ttp.setParameters(
    GENERATIONS=2000,       # Number of generations (iterations)
    POPULATION_SIZE=800,    # Number of individuals per generation
    MUTATION_RATE=0.05,     # Probability of mutation
    CROSSOVER_RATE=0.95,    # Probability of crossover
    ELITE_SIZE=50           # Number of top individuals kept each generation
)
```

#### Parameter Meaning

Each parameter directly influences how your Genetic Algorithm behaves and evolves over time.  
Understanding their effects helps you fine-tune performance and balance exploration with exploitation.

| **Parameter** | **Description** | **Effect on Algorithm** | **Recommended Range** |
|----------------|-----------------|--------------------------|------------------------|
| **GENERATIONS** | Total number of iterations the algorithm will run. | Higher values allow for deeper evolution but increase runtime. | 500 – 10,000 |
| **POPULATION_SIZE** | Number of individuals in each generation. | Larger values improve diversity and stability but increase computational cost. | 100 – 1,000+ |
| **MUTATION_RATE** | Probability of applying random changes to individuals. | High values improve exploration but may reduce convergence speed. | 0.01 – 0.1 |
| **CROSSOVER_RATE** | Probability that two selected parents will crossover to create offspring. | Encourages exploitation by combining good traits; too low may reduce diversity. | 0.8 – 0.99 |
| **ELITE_SIZE** | Number of top individuals preserved unchanged into the next generation. | Maintains high-quality solutions; too large can reduce genetic diversity. | 10 – 50 |
 **Tip:** If your algorithm converges too quickly (fitness stops improving early), try:
- Increasing the **mutation rate**
- Reducing the **elite size**
- Increasing **population size**

If it’s too random and unstable, try:
- Lowering the **mutation rate**
- Increasing the **elite size**
- Reducing **population size**

---

###  Example Parameter Tuning

Here’s a quick Python snippet showing how to experiment with different configurations to find the best-performing setup:

```python
# Example parameter sweep
for population in [200, 400, 800]:
    for mutation in [0.02, 0.05, 0.1]:
        print(f"Running test: POPULATION={population}, MUTATION={mutation}")
        ttp.setParameters(
            GENERATIONS=1000,
            POPULATION_SIZE=population,
            MUTATION_RATE=mutation,
            CROSSOVER_RATE=0.95,
            ELITE_SIZE=30
        )
        ttp(dataset)
```




The CSV log can be plotted to analyze convergence trends, showing how fitness improves with each generation.

---

### Interpreting the Results

- **Fitness** measures how well a given solution balances profit and distance.  
- **Score** typically reflects total distance or another optimization metric depending on the selected fitness method.  
- **Profit and distance** trade-offs evolve over generations — you can compare these to evaluate different configurations.

## Practical Tips

- Start with small values for `POPULATION_SIZE` and `GENERATIONS` to validate your setup quickly.  
- Use the `"mixt"` mode for **crossover** and **mutation** to automatically combine multiple strategies.  
- Try different **selection methods** (`turneu`, `roata`, `choice`) to adjust diversity and convergence speed.  
- To view all available options and methods, simply run:
  ```python
  GeneticAlgorithm().help()
    ```
- To stop the algorithm gracefully mid-run, edit your external command file (`extern_command.cmd`) and set:

    ```yaml
    stop: true
    ```
  This command allows you to safely interrupt long-running optimizations without losing progress or corrupting output logs.  
The algorithm periodically checks this file during execution, so the stop command is detected quickly and handled gracefully.

---

##  Algorithm Workflow
```
Population → Fitness Evaluation → Selection → Crossover → Mutation → New Generation
                   ↑                                                      ↓
              Metrics & Logging   ←  Elitism (best individuals preserved)
```


This cycle represents the **core loop** of the Genetic Algorithm.  
Each stage plays a specific and essential role in the evolutionary process:

- **Population** → The current set of individuals (possible solutions) in the algorithm.  
- **Fitness Evaluation** → Each individual is evaluated based on the chosen objective or metric (for example, total route distance or total profit).  
- **Selection** → The best individuals are selected as parents to produce the next generation.  
- **Crossover** → Parents exchange parts of their genetic material to create new offspring (solutions).  
- **Mutation** → Small random changes are introduced to maintain diversity and prevent stagnation.  
- **New Generation** → The new set of individuals created after crossover and mutation replaces the previous population.  
- **Elitism** → A few of the top-performing individuals are carried forward unchanged to ensure the best traits are preserved.

The algorithm continues through this cycle until:
- The **maximum number of generations** is reached, **or**
- An **external stop command** (`stop: true`) is detected in the `extern_command.cmd` file.

---
###  Key Takeaways

Optimizing a Genetic Algorithm isn’t just about finding “one best” configuration — it’s about balancing parameters to suit your specific problem and dataset.  
Here are the main ideas to keep in mind:

- **Generations** → Define how long the algorithm evolves. More generations give better refinement but increase runtime.  
- **Population size** → Controls diversity. Larger populations explore more possibilities but take longer per iteration.  
- **Mutation rate** → Encourages exploration. Too high makes results chaotic; too low may trap you in local minima.  
- **Crossover rate** → Governs exploitation. Higher values combine good solutions efficiently; lower values maintain more diversity.  
- **Elitism** → Protects the best individuals. A small elite size helps preserve high-quality solutions while still allowing evolution.

To find the right balance:
1. Start with default parameters.  
2. Observe the convergence trend in `logs/history.csv`.  
3. Gradually adjust **mutation**, **elitism**, and **population size** to improve stability and convergence.  

---

###  Example Tuning Workflow

1. **Run baseline tests** with default parameters to ensure stability.  
2. **Increase population size** to see if diversity improves results.  
3. **Adjust mutation rate** (0.01–0.1) to fine-tune exploration.  
4. **Use multiple selection methods** (e.g., `"turneu"` and `"roata"`) for better variety.  
5. **Compare runs** visually using fitness plots from your CSV logs.  

Through systematic experimentation, you’ll quickly learn which configurations best suit your optimization problem.

---
##  Summary

This framework provides a **modular and flexible system** for experimenting with Genetic Algorithms in Python.  
It separates the evolutionary process into independent, replaceable modules, making it perfect for experimentation and learning.

### Key Features:
- Built-in support for **TSP (Travelling Salesman Problem)** and **TTP (Travelling Thief Problem)**  
- Modular architecture — each algorithmic phase (metrics, initialization, selection, crossover, mutation) is customizable  
- Multiple strategies for selection, mutation, and crossover  
- Automatic CSV logging for performance tracking  
- Optional route visualization and safe external stop control  

---

### Final Thoughts

This project provides a **powerful yet easy-to-understand framework** for implementing and experimenting with Genetic Algorithms in Python.  
It focuses on clarity, modularity, and adaptability — making it suitable for **students, researchers, and developers** alike.

Whether you're studying evolutionary computation concepts, optimizing real-world problems, or designing your own operators, this framework gives you full control over every component of the algorithm.

---